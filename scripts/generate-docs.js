#!/usr/bin/env node
/**
 * generate-docs.js — Auto-generate reference documentation from source code.
 *
 * Produces three files:
 *   docs/api-reference.md   — Exported functions, signatures, params, caller graph
 *   docs/dependencies.md    — NPM packages, Python imports, configuration constants
 *   docs/data-flow.md       — Module input/output contracts (JSON artifacts)
 *
 * Usage: node scripts/generate-docs.js
 * No dependencies beyond Node.js builtins (fs, path).
 */

const fs = require('fs');
const path = require('path');

const ROOT = path.resolve(__dirname, '..');
const LIB_DIR = path.join(ROOT, 'scripts', 'quality', 'lib');
const QUALITY_DIR = path.join(ROOT, 'scripts', 'quality');
const ORCHESTRATE_PATH = path.join(ROOT, 'scripts', 'orchestrate.py');
const PACKAGE_JSON_PATH = path.join(QUALITY_DIR, 'package.json');
const DOCS_DIR = path.join(ROOT, 'docs');

// ─── Helpers ───────────────────────────────────────────────────────────────────

function getSourceFiles() {
  const libFiles = fs.readdirSync(LIB_DIR)
    .filter(f => f.endsWith('.js'))
    .sort()
    .map(f => ({ name: f, dir: 'lib', fullPath: path.join(LIB_DIR, f) }));

  const qualityFiles = fs.readdirSync(QUALITY_DIR)
    .filter(f => f.endsWith('.js'))
    .sort()
    .map(f => ({ name: f, dir: 'quality', fullPath: path.join(QUALITY_DIR, f) }));

  return [...libFiles, ...qualityFiles];
}

function lineCount(filePath) {
  return fs.readFileSync(filePath, 'utf8').split('\n').length;
}

// ─── Output 1: API Reference ──────────────────────────────────────────────────

function extractFunctions(content) {
  const fns = [];
  const lines = content.split('\n');

  for (let i = 0; i < lines.length; i++) {
    const line = lines[i];

    // Match: function name(params) {
    const fnMatch = line.match(/^(?:async\s+)?function\s+(\w+)\s*\(([^)]*)\)/);
    if (fnMatch) {
      const jsdoc = extractJSDoc(lines, i);
      fns.push({
        name: fnMatch[1],
        params: fnMatch[2].trim(),
        line: i + 1,
        jsdoc,
      });
    }
  }
  return fns;
}

function extractJSDoc(lines, fnLineIndex) {
  // Look backward from the function line for a JSDoc block
  let end = fnLineIndex - 1;
  while (end >= 0 && lines[end].trim() === '') end--;
  if (end < 0 || !lines[end].trim().endsWith('*/')) return null;

  let start = end;
  while (start > 0 && !lines[start].includes('/**')) start--;
  if (!lines[start].includes('/**')) return null;

  const block = lines.slice(start, end + 1).join('\n');
  const result = {};

  // Extract @param tags
  const paramMatches = [...block.matchAll(/@param\s+\{([^}]+)\}\s+(\w+)\s*[-–—]?\s*(.*)/g)];
  if (paramMatches.length) {
    result.params = paramMatches.map(m => ({
      type: m[1],
      name: m[2],
      desc: m[3].trim(),
    }));
  }

  // Extract @returns
  const retMatch = block.match(/@returns?\s+\{([^}]+)\}\s*(.*)/);
  if (retMatch) {
    result.returns = { type: retMatch[1], desc: retMatch[2].trim() };
  }

  // Extract description (first line after /**)
  const descMatch = block.match(/\/\*\*\s*\n\s*\*\s+(.+)/);
  if (descMatch) {
    result.description = descMatch[1].replace(/^\*\s*/, '').trim();
  }

  return Object.keys(result).length > 0 ? result : null;
}

function extractExports(content) {
  // Match: module.exports = { a, b, c }
  const match = content.match(/module\.exports\s*=\s*\{([^}]+)\}/);
  if (!match) return [];
  return match[1].split(',').map(s => s.trim()).filter(Boolean);
}

function buildCallerGraph(files) {
  // Map: module name → which files require it
  const graph = {};

  for (const file of files) {
    const content = fs.readFileSync(file.fullPath, 'utf8');
    const requireMatches = [...content.matchAll(/require\(['"]\.\/(?:lib\/)?([^'"]+)['"]\)/g)];

    for (const m of requireMatches) {
      let target = m[1];
      if (!target.endsWith('.js')) target += '.js';
      if (!graph[target]) graph[target] = [];
      graph[target].push(file.name);
    }
  }

  // Also check orchestrate.py for subprocess calls to JS files
  if (fs.existsSync(ORCHESTRATE_PATH)) {
    const pyContent = fs.readFileSync(ORCHESTRATE_PATH, 'utf8');
    const subprocMatches = [...pyContent.matchAll(/(?:node|subprocess).*?(\w[\w-]+\.js)/g)];
    for (const m of subprocMatches) {
      const target = m[1];
      if (!graph[target]) graph[target] = [];
      if (!graph[target].includes('orchestrate.py')) {
        graph[target].push('orchestrate.py');
      }
    }
  }

  return graph;
}

function generateApiReference(files) {
  const callerGraph = buildCallerGraph(files);
  const lines = [
    '# API Reference',
    '',
    `> Auto-generated by \`node scripts/generate-docs.js\` on ${new Date().toISOString().split('T')[0]}`,
    '> Do not edit manually — regenerate from source.',
    '',
    '---',
    '',
  ];

  // Group: lib files first, then top-level quality scripts
  const libFiles = files.filter(f => f.dir === 'lib');
  const topFiles = files.filter(f => f.dir === 'quality');

  for (const group of [
    { title: 'Library Modules (`scripts/quality/lib/`)', files: libFiles },
    { title: 'Top-Level Scripts (`scripts/quality/`)', files: topFiles },
  ]) {
    lines.push(`## ${group.title}`, '');

    for (const file of group.files) {
      const content = fs.readFileSync(file.fullPath, 'utf8');
      const lc = lineCount(file.fullPath);
      const exports = extractExports(content);
      const functions = extractFunctions(content);
      const callers = callerGraph[file.name] || [];

      lines.push(`### ${file.name} (${lc} lines)`, '');

      if (callers.length) {
        lines.push(`**Called by:** ${callers.join(', ')}`, '');
      }

      if (exports.length) {
        lines.push('**Exports:** `' + exports.join('`, `') + '`', '');
      }

      // Show exported functions first, then internal
      const exportedFns = functions.filter(f => exports.includes(f.name));
      const internalFns = functions.filter(f => !exports.includes(f.name));

      if (exportedFns.length) {
        lines.push('#### Exported Functions', '');
        for (const fn of exportedFns) {
          lines.push(`##### \`${fn.name}(${fn.params})\` <sub>line ${fn.line}</sub>`, '');
          if (fn.jsdoc) {
            if (fn.jsdoc.description) {
              lines.push(fn.jsdoc.description, '');
            }
            if (fn.jsdoc.params) {
              for (const p of fn.jsdoc.params) {
                lines.push(`- **${p.name}** \`${p.type}\` — ${p.desc}`);
              }
              lines.push('');
            }
            if (fn.jsdoc.returns) {
              lines.push(`- **Returns:** \`${fn.jsdoc.returns.type}\` ${fn.jsdoc.returns.desc}`, '');
            }
          }
        }
      }

      if (internalFns.length) {
        lines.push('#### Internal Functions', '');
        for (const fn of internalFns) {
          lines.push(`- \`${fn.name}(${fn.params})\` <sub>line ${fn.line}</sub>`);
        }
        lines.push('');
      }

      lines.push('---', '');
    }
  }

  return lines.join('\n');
}

// ─── Output 2: Dependencies ───────────────────────────────────────────────────

function generateDependencies(files) {
  const lines = [
    '# Dependencies & Configuration',
    '',
    `> Auto-generated by \`node scripts/generate-docs.js\` on ${new Date().toISOString().split('T')[0]}`,
    '> Do not edit manually — regenerate from source.',
    '',
    '---',
    '',
  ];

  // NPM Dependencies
  if (fs.existsSync(PACKAGE_JSON_PATH)) {
    const pkg = JSON.parse(fs.readFileSync(PACKAGE_JSON_PATH, 'utf8'));
    const deps = pkg.dependencies || {};

    // Build usage map: package → files that require it
    const usageMap = {};
    for (const file of files) {
      const content = fs.readFileSync(file.fullPath, 'utf8');
      for (const pkgName of Object.keys(deps)) {
        if (content.includes(`require('${pkgName}')`) || content.includes(`require("${pkgName}")`)) {
          if (!usageMap[pkgName]) usageMap[pkgName] = [];
          usageMap[pkgName].push(file.name);
        }
      }
    }

    lines.push('## NPM Dependencies', '');
    lines.push('| Package | Version | Used By |');
    lines.push('|---------|---------|---------|');
    for (const [name, version] of Object.entries(deps).sort()) {
      const usedBy = (usageMap[name] || []).join(', ') || '(indirect)';
      lines.push(`| ${name} | ${version} | ${usedBy} |`);
    }
    lines.push('');
  }

  // Python imports from orchestrate.py
  if (fs.existsSync(ORCHESTRATE_PATH)) {
    const pyContent = fs.readFileSync(ORCHESTRATE_PATH, 'utf8');
    const imports = new Set();
    const importMatches = [...pyContent.matchAll(/^(?:import|from)\s+([\w.]+)/gm)];
    for (const m of importMatches) {
      imports.add(m[1].split('.')[0]);
    }
    const stdlibSkip = new Set(['os', 'sys', 'json', 're', 'pathlib', 'subprocess', 'shutil', 'textwrap', 'argparse', 'uuid', 'datetime', 'time', 'typing', 'collections', 'functools', 'itertools', 'copy', 'io', 'math', 'hashlib']);
    const thirdParty = [...imports].filter(i => !stdlibSkip.has(i)).sort();

    if (thirdParty.length) {
      lines.push('## Python Dependencies (orchestrate.py)', '');
      lines.push('| Package | Used In |');
      lines.push('|---------|---------|');
      for (const pkg of thirdParty) {
        lines.push(`| ${pkg} | orchestrate.py |`);
      }
      lines.push('');
    }
  }

  // Configuration constants
  lines.push('## Configuration Constants', '');
  lines.push('| Constant | Value | File | Line |');
  lines.push('|----------|-------|------|------|');

  // JS constants from lib files
  for (const file of files.filter(f => f.dir === 'lib')) {
    const content = fs.readFileSync(file.fullPath, 'utf8');
    const fileLines = content.split('\n');
    for (let i = 0; i < fileLines.length; i++) {
      const match = fileLines[i].match(/^const\s+([A-Z][A-Z0-9_]+)\s*=\s*(.+?);?\s*$/);
      if (match) {
        let val = match[2].trim();
        // Clean up long values
        if (val.length > 60) val = val.substring(0, 57) + '...';
        // Skip object/array literals (they're maps, not simple constants)
        if (val.startsWith('{') || val.startsWith('[')) continue;
        lines.push(`| \`${match[1]}\` | \`${val}\` | ${file.name} | ${i + 1} |`);
      }
    }
  }

  // Python constants from orchestrate.py
  if (fs.existsSync(ORCHESTRATE_PATH)) {
    const pyContent = fs.readFileSync(ORCHESTRATE_PATH, 'utf8');
    const pyLines = pyContent.split('\n');
    for (let i = 0; i < pyLines.length; i++) {
      const match = pyLines[i].match(/^([A-Z][A-Z0-9_]+)\s*=\s*(.+)/);
      if (match) {
        let val = match[2].trim();
        if (val.length > 60) val = val.substring(0, 57) + '...';
        if (val.startsWith('{') || val.startsWith('[') || val.startsWith('Path(')) continue;
        lines.push(`| \`${match[1]}\` | \`${val}\` | orchestrate.py | ${i + 1} |`);
      }
    }
  }

  lines.push('');
  return lines.join('\n');
}

// ─── Output 3: Data Flow ─────────────────────────────────────────────────────

function generateDataFlow(files) {
  const lines = [
    '# Data Flow',
    '',
    `> Auto-generated by \`node scripts/generate-docs.js\` on ${new Date().toISOString().split('T')[0]}`,
    '> Do not edit manually — regenerate from source.',
    '',
    'Maps every JSON artifact and data structure to its producer and consumer modules.',
    'Combines static analysis (file I/O detection) with require-graph tracing.',
    '',
    '---',
    '',
  ];

  const libFiles = files.filter(f => f.dir === 'lib');
  const allFiles = files;

  // Build require graph: file → [files it requires]
  const requireGraph = {};
  // Build reverse require graph: file → [files that require it]
  const requiredByGraph = {};

  for (const file of allFiles) {
    const content = fs.readFileSync(file.fullPath, 'utf8');
    const requires = [...content.matchAll(/require\(['"]\.\/(?:lib\/)?([^'"]+)['"]\)/g)].map(m => {
      let t = m[1];
      if (!t.endsWith('.js')) t += '.js';
      return t;
    });
    requireGraph[file.name] = requires;
    for (const req of requires) {
      if (!requiredByGraph[req]) requiredByGraph[req] = [];
      requiredByGraph[req].push(file.name);
    }
  }

  // Detect file I/O per module
  for (const file of libFiles) {
    const content = fs.readFileSync(file.fullPath, 'utf8');
    const lc = lineCount(file.fullPath);
    const exports = extractExports(content);

    const reads = [];
    const writes = [];

    // Detect fs.readFileSync with identifiable filenames (exclude encoding args like 'utf8')
    for (const m of content.matchAll(/fs\.readFileSync\s*\(([^)]+)\)/g)) {
      const arg = m[1];
      const strMatch = arg.match(/['"]([^'"]+\.\w{2,4})['"]/);
      if (strMatch) reads.push(strMatch[1]);
    }

    // Detect fs.writeFileSync with identifiable filenames
    for (const m of content.matchAll(/fs\.writeFileSync\s*\(([^,]+)/g)) {
      const arg = m[1];
      const strMatch = arg.match(/['"]([^'"]+\.(?:json|png|md|txt|css|js|tsx?))['"]/);
      if (strMatch) writes.push(strMatch[1]);
      // Also catch path.join constructions with known filenames
      const joinMatch = arg.match(/path\.join\s*\([^)]*?,\s*['"]([^'"]+)['"]\s*\)/);
      if (joinMatch) writes.push(joinMatch[1]);
    }

    // Detect known JSON artifact references
    const knownArtifacts = [
      'extraction-data.json', 'mapped-sections.json', 'animation-analysis.json',
      'animation-summary.json', 'asset-manifest.json', 'design-tokens.json',
    ];
    const referencedArtifacts = knownArtifacts.filter(a => content.includes(a));

    const requires = requireGraph[file.name] || [];
    const requiredBy = requiredByGraph[file.name] || [];

    lines.push(`### ${file.name} (${lc} lines)`);
    lines.push('');

    if (exports.length) {
      lines.push(`**Exports:** ${exports.map(e => '`' + e + '()`').join(', ')}`);
    }

    if (requires.length) {
      lines.push(`**Requires:** ${requires.map(r => '`' + r + '`').join(', ')}`);
    }

    if (requiredBy.length) {
      lines.push(`**Required by:** ${requiredBy.map(r => '`' + r + '`').join(', ')}`);
    }

    if (reads.length) {
      lines.push(`**Reads:** ${reads.map(r => '`' + r + '`').join(', ')}`);
    }

    if (writes.length) {
      lines.push(`**Writes:** ${writes.map(w => '`' + w + '`').join(', ')}`);
    }

    if (referencedArtifacts.length) {
      lines.push(`**References artifacts:** ${referencedArtifacts.map(a => '`' + a + '`').join(', ')}`);
    }

    lines.push('', '---', '');
  }

  // Also document top-level scripts
  const topFiles = files.filter(f => f.dir === 'quality');
  if (topFiles.length) {
    lines.push('## Top-Level Scripts', '');
    for (const file of topFiles) {
      const content = fs.readFileSync(file.fullPath, 'utf8');
      const requires = requireGraph[file.name] || [];
      if (requires.length === 0) continue;
      lines.push(`### ${file.name}`);
      lines.push('');
      lines.push(`**Requires:** ${requires.map(r => '`' + r + '`').join(', ')}`);
      lines.push('', '---', '');
    }
  }

  // Orchestrate.py data flow
  if (fs.existsSync(ORCHESTRATE_PATH)) {
    lines.push('## orchestrate.py Subprocess Calls', '');
    const pyContent = fs.readFileSync(ORCHESTRATE_PATH, 'utf8');

    // Find JS scripts referenced in orchestrate.py (via variable names and string literals)
    const jsFileRefs = [...pyContent.matchAll(/["']([^"']*?[\w-]+\.js)["']/g)];
    const scriptPathVars = [...pyContent.matchAll(/(\w+_script)\s*=\s*.*?["']([^"']+\.js)["']/g)];
    const allJsRefs = [
      ...jsFileRefs.map(m => path.basename(m[1])),
      ...scriptPathVars.map(m => path.basename(m[2])),
    ];
    // Also match patterns like QUALITY_DIR / "url-to-preset.js"
    const qualityDirRefs = [...pyContent.matchAll(/QUALITY_DIR\s*\/\s*["']([^"']+\.js)["']/g)];
    for (const m of qualityDirRefs) allJsRefs.push(m[1]);
    // Also match lib/ path references
    const libRefs = [...pyContent.matchAll(/["']lib\/([^"']+\.js)["']/g)];
    for (const m of libRefs) allJsRefs.push(m[1]);
    // Match require('./lib/module') patterns in embedded Node.js scripts within Python
    const requireRefs = [...pyContent.matchAll(/require\s*\(\s*['"]\.\/lib\/([^'"]+)['"]\s*\)/g)];
    for (const m of requireRefs) {
      let name = m[1];
      if (!name.endsWith('.js')) name += '.js';
      allJsRefs.push(name);
    }

    const calledScripts = [...new Set(allJsRefs)].filter(s =>
      !s.includes('node_modules') && !s.includes('{') && !s.includes('}')
    ).sort();

    if (calledScripts.length) {
      lines.push('**Calls via subprocess:**');
      for (const script of calledScripts) {
        lines.push(`- \`${script}\``);
      }
      lines.push('');
    }

    // Find JSON file reads/writes in Python
    const pyJsonReads = [...pyContent.matchAll(/json\.load\w*\s*\(.*?["']([^"']+\.json)["']/g)];
    const pyJsonWrites = [...pyContent.matchAll(/json\.dump\w*\s*\(.*?["']([^"']+\.json)["']/g)];

    if (pyJsonReads.length || pyJsonWrites.length) {
      if (pyJsonReads.length) {
        lines.push(`**Reads:** ${pyJsonReads.map(m => '`' + m[1] + '`').join(', ')}`);
      }
      if (pyJsonWrites.length) {
        lines.push(`**Writes:** ${pyJsonWrites.map(m => '`' + m[1] + '`').join(', ')}`);
      }
      lines.push('');
    }

    lines.push('---', '');
  }

  // Pipeline summary diagram
  lines.push('## Pipeline Data Flow Summary', '');
  lines.push('```');
  lines.push('extract-reference.js');
  lines.push('    ├── extraction-data.json');
  lines.push('    │   ├── design-tokens.js → tokens for preset');
  lines.push('    │   ├── archetype-mapper.js → mapped-sections.json');
  lines.push('    │   ├── animation-detector.js → animation-analysis.json');
  lines.push('    │   ├── asset-injector.js → per-section asset context');
  lines.push('    │   └── section-context.js → per-section prompt context');
  lines.push('    └── screenshots/');
  lines.push('');
  lines.push('animation-detector.js + gsap-extractor.js');
  lines.push('    └── animation-analysis.json');
  lines.push('        └── animation-injector.js → per-section animation context');
  lines.push('            ├── registry.json (component library)');
  lines.push('            └── animation-summarizer.js (extracted signatures)');
  lines.push('');
  lines.push('orchestrate.py');
  lines.push('    ├── Calls: url-to-preset.js, url-to-brief.js (Stage 0)');
  lines.push('    ├── Calls: animation-injector.js, asset-injector.js (Stage 2)');
  lines.push('    └── Calls: post-process.js (Stage 2 cleanup)');
  lines.push('```');
  lines.push('');

  return lines.join('\n');
}

// ─── Main ─────────────────────────────────────────────────────────────────────

function main() {
  console.log('[generate-docs] Scanning source files...');

  const files = getSourceFiles();
  console.log(`  Found ${files.length} JS files (${files.filter(f => f.dir === 'lib').length} lib, ${files.filter(f => f.dir === 'quality').length} top-level)`);

  // Ensure docs/ directory exists
  if (!fs.existsSync(DOCS_DIR)) {
    fs.mkdirSync(DOCS_DIR, { recursive: true });
  }

  // Generate all three docs
  const apiRef = generateApiReference(files);
  const deps = generateDependencies(files);
  const dataFlow = generateDataFlow(files);

  // Write atomically
  const outputs = [
    { name: 'api-reference.md', content: apiRef },
    { name: 'dependencies.md', content: deps },
    { name: 'data-flow.md', content: dataFlow },
  ];

  for (const out of outputs) {
    const outPath = path.join(DOCS_DIR, out.name);
    fs.writeFileSync(outPath, out.content, 'utf8');
    const lines = out.content.split('\n').length;
    console.log(`  ✓ ${out.name} (${lines} lines)`);
  }

  console.log('[generate-docs] Done.');
}

main();
